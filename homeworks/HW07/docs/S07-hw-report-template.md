# HW07 – Report

> Файл: `homeworks/HW07/report.md`

## 1. Datasets

Выбраны 3 датасета из 4:

### 1.1 Dataset A (S07-hw-dataset-01.csv)

- Файл: `S07-hw-dataset-01.csv`
- Размер: 15000 строк, несколько числовых столбцов
- Признаки: только числовые
- Пропуски: отсутствуют
- "Подлости" датасета: 
  - Чёткая структура с 4 выраженными кластерами
  - Различные масштабы признаков (требуется обязательное масштабирование)
  - Кластеры имеют сферическую форму, что идеально для KMeans
  - Один крупный кластер и три меньших по размеру

### 1.2 Dataset B (S07-hw-dataset-02.csv)

- Файл: `S07-hw-dataset-02.csv`
- Размер: 12000 строк
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета:
  - Два крупных кластера с примерно одинаковой плотностью
  - Линейно разделимые группы
  - Относительно простая структура для всех алгоритмов
  - DBSCAN показывает слабые результаты (отрицательный Silhouette при больших eps)

### 1.3 Dataset C (S07-hw-dataset-03.csv)

- Файл: `S07-hw-dataset-03.csv`
- Размер: около 12000 строк
- Признаки: числовые
- Пропуски: отсутствуют
- "Подлости" датасета:
  - Три кластера разной плотности и формы
  - Один кластер имеет вытянутую нелинейную структуру
  - Частичное перекрытие между группами
  - DBSCAN испытывает трудности с выбором оптимального eps

## 2. Protocol

### Препроцессинг

Применялся единый pipeline для всех датасетов:
- **Imputation**: `SimpleImputer(strategy='median')` для обработки потенциальных пропусков
- **Scaling**: `StandardScaler()` для нормализации всех числовых признаков (критично для distance-based методов)
- Категориальные признаки и PCA не использовались (все датасеты содержат только числовые признаки)

### Поиск гиперпараметров

**KMeans:**
- Диапазон k: от 2 до 10
- Фиксация: `random_state=42`, `n_init=10`
- Критерий выбора: максимум Silhouette Score

**DBSCAN:**
- Диапазон eps: [0.3, 0.5, 0.7, 1.0, 1.5]
- `min_samples=5` (фиксировано)
- Критерий: максимум Silhouette Score на non-noise точках

**Agglomerative Clustering:**
- Использован `linkage='ward'`
- Число кластеров: соответствует лучшему k из KMeans для каждого датасета

### Метрики

Для оценки качества использовались:
- **Silhouette Score** ([-1, 1], выше — лучше): измеряет компактность и разделимость кластеров
- **Davies-Bouldin Score** ([0, ∞), ниже — лучше): отношение внутрикластерного разброса к межкластерному расстоянию
- **Calinski-Harabasz Score** ([0, ∞), выше — лучше): отношение межкластерной дисперсии к внутрикластерной

Для DBSCAN метрики считались только на точках, не отмеченных как шум (label ≠ -1).

### Визуализация

- **PCA(2D)**: использовался для всех итоговых визуализаций с `random_state=42`
- Показывается процент объяснённой дисперсии по каждой компоненте
- t-SNE не применялся в данной работе

## 3. Models

### Dataset 1 (S07-hw-dataset-01.csv)

**KMeans:**
- Поиск k в диапазоне [2, 10]
- Лучший результат: k=2 (Silhouette=0.525)
- Фиксация: `random_state=42`, `n_init=10`

**DBSCAN:**
- Поиск eps в [0.3, 0.5, 0.7, 1.0, 1.5]
- `min_samples=5`
- Лучший результат: eps=1.5 (Silhouette=0.398)
- Доля шума варьировалась от 0% до ~15% в зависимости от eps

**Agglomerative:**
- `n_clusters=2`, `linkage='ward'`
- Silhouette=0.506

### Dataset 2 (S07-hw-dataset-02.csv)

**KMeans:**
- Диапазон k: [2, 10]
- Лучший k=2 (Silhouette=0.295)

**DBSCAN:**
- Диапазон eps: [0.3, 0.5, 0.7, 1.0, 1.5]
- При eps≥0.7 Silhouette=-1.0 (все точки попадают в один кластер или шум)
- Лучший eps=0.3 (Silhouette=0.087)

**Agglomerative:**
- `n_clusters=2`, `linkage='ward'`
- Silhouette=0.295

### Dataset 3 (S07-hw-dataset-03.csv)

**KMeans:**
- Диапазон k: [2, 10]
- Лучший k=3 (Silhouette=0.315)

**DBSCAN:**
- Диапазон eps: [0.3, 0.5, 0.7, 1.0, 1.5]
- При eps≥0.7 результаты деградируют
- Лучший eps=0.5 (Silhouette=-0.096)

**Agglomerative:**
- `n_clusters=3`, `linkage='ward'`
- Silhouette=0.305

## 4. Results

### 4.1 Dataset A (S07-hw-dataset-01.csv)

**Лучший метод:** KMeans с k=2

**Метрики:**
- Silhouette: 0.525
- Davies-Bouldin: 0.628
- Calinski-Harabasz: 17890.3

**Анализ:** Датасет имеет чёткую двухкластерную структуру. На PCA-графике видны 4 визуальные группы, но алгоритм объединил их в 2 крупных кластера. KMeans показал превосходные результаты благодаря сферической форме кластеров и хорошей разделимости. DBSCAN также работает приемлемо, но требует тщательного подбора eps.

### 4.2 Dataset B (S07-hw-dataset-02.csv)

**Лучший метод:** KMeans / Agglomerative (одинаковый результат, k=2)

**Метрики:**
- Silhouette: 0.295
- Davies-Bouldin: 1.429
- Calinski-Harabasz: 3689.5

**Анализ:** Два кластера с умеренной разделимостью. Метрики значительно ниже, чем для Dataset 1, что указывает на большее перекрытие между группами. DBSCAN показал очень плохие результаты — при малых eps создаёт слишком много шума, при больших eps все точки попадают в один кластер. KMeans справляется лучше благодаря своей способности работать с перекрывающимися группами.

### 4.3 Dataset C (S07-hw-dataset-03.csv)

**Лучший метод:** KMeans с k=3

**Метрики:**
- Silhouette: 0.315
- Davies-Bouldin: 1.316
- Calinski-Harabasz: 5472.1

**Анализ:** Три кластера разной формы и плотности. На PCA-графике видна нелинейная структура одного из кластеров (вытянутая дугообразная форма). KMeans выбран как лучший метод, несмотря на не идеальную форму кластеров. DBSCAN не смог найти хорошее решение — все протестированные значения eps давали отрицательный Silhouette или помечали большую часть данных как шум.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

**Где KMeans "ломается":**
- KMeans предполагает сферическую форму кластеров и примерно одинаковые размеры
- На Dataset 3 видно, что при наличии вытянутых нелинейных структур KMeans даёт субоптимальное разбиение
- Алгоритм чувствителен к масштабу признаков — без StandardScaler результаты значительно хуже

**Где DBSCAN/иерархическая кластеризация выигрывают:**
- DBSCAN теоретически лучше для нелинейных форм и может игнорировать шум
- Однако на всех трёх датасетах DBSCAN показал худшие результаты, чем KMeans
- Проблема DBSCAN: очень чувствителен к выбору eps, который сильно зависит от плотности данных
- Agglomerative с ward linkage показывает результаты, почти идентичные KMeans

**Что сильнее всего влияло на результат:**
1. **Масштабирование** — критически важно для всех distance-based методов
2. **Форма кластеров** — сферические vs вытянутые/нелинейные
3. **Разделимость групп** — чем сильнее перекрытие, тем ниже метрики
4. **Выбор параметров** — особенно eps для DBSCAN

### 5.2 Устойчивость (проверка на всех датасетах)

Проверялась устойчивость KMeans при изменении `random_state` (5 запусков с разными seed).

**Dataset 1:**
- ARI scores: [0.998, 0.999, 1.000, 0.999, 1.000]
- Средний ARI: 0.999 ± 0.001
- **Вывод:** Очень высокая устойчивость

**Dataset 2:**
- ARI scores: [1.000, 1.000, 1.000, 1.000, 1.000]
- Средний ARI: 1.000 ± 0.000
- **Вывод:** Абсолютная устойчивость (идентичное разбиение)

**Dataset 3:**
- ARI scores: [0.989, 0.991, 0.993, 0.990, 0.992]
- Средний ARI: 0.991 ± 0.001
- **Вывод:** Очень высокая устойчивость

**Общий вывод:** KMeans демонстрирует высокую устойчивость на всех датасетах. Это связано с хорошей начальной инициализацией центроидов (`n_init=10`) и чёткой структурой данных. Небольшие вариации (ARI > 0.99) не влияют на качество итогового разбиения.

### 5.3 Интерпретация кластеров

**Подход к интерпретации:** анализ профилей через средние значения признаков в каждом кластере и визуальный анализ PCA-проекций.

**Основные наблюдения:**

- **Dataset 1:** Четыре визуальные группы на PCA объединены в 2 кластера. Один кластер содержит компактную группу слева, второй — три группы справа. Разделение произошло по первой главной компоненте (54.6% дисперсии).

- **Dataset 2:** Два кластера примерно равного размера с частичным перекрытием в центральной области. Разделение идёт по первой главной компоненте (42.5% дисперсии). Перекрытие объясняет умеренные значения метрик.

- **Dataset 3:** Три кластера разной формы. Один имеет компактную круглую форму (фиолетовый), второй — вытянутую структуру (бирюзовый), третий — также компактный (жёлтый). PC1 объясняет 44.2%, PC2 — 27.8% дисперсии. Нелинейная структура среднего кластера показывает ограничения KMeans.

## 6. Conclusion

Ключевые выводы о кластеризации и unsupervised-эксперименте:

1. **Препроцессинг критичен:** StandardScaler обязателен для distance-based методов. Без масштабирования результаты непредсказуемы.

2. **KMeans — надёжный baseline:** несмотря на ограничения (сферические кластеры), показывает стабильно хорошие результаты на разных типах данных.

3. **DBSCAN требует опыта:** подбор eps — нетривиальная задача. На наших данных DBSCAN систематически уступал KMeans.

4. **Метрики дополняют друг друга:** Silhouette хорош для общей оценки, Davies-Bouldin и Calinski-Harabasz дают дополнительную информацию. Важно смотреть на все метрики в комплексе.

5. **Визуализация необходима:** PCA помогает понять структуру данных и объяснить результаты алгоритмов. Метрики без визуализации дают неполную картину.

6. **Устойчивость подтверждает качество:** высокий ARI между разными запусками говорит о надёжности найденного решения.

7. **Нет универсального метода:** выбор алгоритма зависит от структуры данных (форма кластеров, плотность, шум).

8. **Честный протокол важен:** отсутствие истинных меток требует особой аккуратности в выборе метрик и интерпретации результатов.