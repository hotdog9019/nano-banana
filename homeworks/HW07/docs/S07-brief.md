# Семинар 07 – Кластеризация, метрики и снижение размерности (PCA / t-SNE)

## 1. Место в курсе

Седьмой семинар курса «Инженерия Искусственного Интеллекта».

Опирается на лекцию **L07** (кластеризация, метрики качества без меток, PCA/t-SNE) и продолжает линию "инженерной дисциплины эксперимента", начатую в **S05-S06**:

- в supervised-ML мы умеем честно сравнивать модели через train/test + CV;
- в unsupervised-ML (кластеризация) часто **нет истинных меток**, поэтому честный подход – это
  **протокол сравнения** (препроцессинг → кандидаты → подбор параметров → внутренние метрики → визуализация → интерпретация).

Домашнее задание по семинару – **HW07**, формальное описание находится в файле `seminars/S07/S07-homework.md`.

---

## 2. Цели семинара

После семинара и выполнения домашнего задания студент:

- понимает, что такое кластеризация как задача обучения **без учителя** и какие вопросы она реально решает (поиск групп/структуры, сегментация, первичная разведка данных);
- знает три базовых "семейства" методов и их типичные сценарии:
  - **KMeans** – быстро, просто, хорошо для "примерно шарообразных" кластеров и табличных данных (при правильном scaling);
  - **DBSCAN** – плотностная логика, умеет шум/выбросы, подходит для нелинейных форм кластеров;
  - **Agglomerative (иерархическая)** – дерево объединений, влияние `linkage`, дендрограмма как инструмент анализа;
- умеет корректно оценивать качество кластеризации **без истинных меток**:
  - `silhouette_score`, `davies_bouldin_score`, `calinski_harabasz_score` и смысл каждой метрики;
  - понимает, что "оптимизируем метрику → получаем то, что она поощряет";
- умеет делать базовую визуализацию и анализ структуры данных:
  - **PCA** для снижения размерности/визуализации/ускорения;
  - **t-SNE** как визуализация локальной структуры (с правильной интерпретацией и фиксацией `random_state`);
- умеет собрать "инженерный" unsupervised-эксперимент: единый препроцессинг, подбор параметров, сводка метрик, сохранение артефактов (графики, json, labels).

---

## 3. Краткое содержание

1. **Вступление и связь с S05-S06**
   - чем отличается "честный эксперимент" в supervised и unsupervised;
   - почему без корректного препроцессинга и протокола сравнения кластеризацию легко "самообмануть".

2. **Demo 1: KMeans – базовая механика и выбор `k`**
   - интуиция алгоритма;
   - почему масштабирование признаков критично;
   - подбор `k` (эвристика elbow + silhouette);
   - короткая проверка устойчивости через `n_init`/`random_state`.

   Файл: `S07-demo-01-kmeans-basics-and-k-selection.ipynb`

3. **Demo 2: DBSCAN – плотность, шум и выбросы**
   - идея `eps` и `min_samples`;
   - что значит `label = -1` (noise) и почему это полезно;
   - примеры "нелинейных" кластеров и датасетов с выбросами;
   - аккуратный расчёт метрик при наличии шума (обычно по non-noise точкам).

   Файл: `S07-demo-02-dbscan-density-and-noise.ipynb`

4. **Demo 3: Иерархическая кластеризация и дендрограмма**
   - логика последовательных объединений;
   - влияние `linkage` (ward/complete/average/single);
   - чтение дендрограммы и выбор числа кластеров;
   - визуализация результата через PCA(2D).

   Файл: `S07-demo-03-hierarchical-clustering-and-dendrogram.ipynb`

5. **Demo 4: Внутренние метрики + PCA + t-SNE**
   - silhouette / Davies-Bouldin / Calinski-Harabasz: как интерпретировать и сравнивать варианты;
   - PCA: explained variance, 2D-карта и зачем PCA полезна перед t-SNE;
   - t-SNE: как запускать и как НЕ интерпретировать (локальная структура, зависимость от параметров).

   Файл: `S07-demo-04-cluster-metrics-pca-tsne.ipynb`

6. **Demo 5: Инженерный unsupervised-эксперимент – единый протокол**
   - единый препроцессинг (scaling + опционально PCA);
   - кандидаты: KMeans / DBSCAN / Agglomerative;
   - перебор параметров "в меру" и честная сводка метрик;
   - итоговая визуализация и минимальная интерпретация;
   - фиксация артефактов (метрики/параметры/labels/графики).

   Файл: `S07-demo-05-engineering-unsupervised-experiment.ipynb`

---

## 4. Формат проведения

Семинар проводится в формате "короткая рамка → серия демо → инженерная сборка → постановка HW07".

- **Короткий разбор (начало занятия)**:
  - связь S07 с L07 и с инженерной дисциплиной S05-S06;
  - ключевой вопрос семинара: "как честно сравнивать кластеризацию, когда меток нет?"

- **Практическая часть (основное время, live-coding + обсуждение)**:
  - 5 ноутбуков-демонстраций (по нарастающей сложности):
    1) KMeans и выбор `k`;
    2) DBSCAN и шум/выбросы;
    3) Иерархическая кластеризация и дендрограмма;
    4) Метрики + PCA + t-SNE;
    5) Инженерный протокол (сводка и фиксация результатов);
  - по ходу – короткие контрольные вопросы:
    - где именно scaling меняет ответ и почему;
    - почему DBSCAN может "всё сделать шумом" или "всё слить в один кластер";
    - чем linkage отличается по смыслу;
    - почему t-SNE нельзя использовать как "доказательство качества кластеров".

- **Постановка домашнего задания (финал)**:
  - демонстрация ожидаемой структуры `homeworks/HW07/`;
  - объяснение набора CSV для HW07 и почему они специально сделаны "неровными";
  - акцент: важны не только метрики, но и протокол, интерпретация и артефакты.

---

## 5. Результат для студента

К концу семинара студент:

- понимает сильные/слабые стороны KMeans, DBSCAN и иерархической кластеризации;
- умеет выбирать подход под структуру данных (форма кластеров, плотность, выбросы, размерность);
- умеет аккуратно сравнивать варианты кластеризации без истинных меток и делать осмысленные выводы.

После выполнения HW07 у студента в репозитории есть папка `homeworks/HW07/` с:

- ноутбуком `HW07.ipynb`, где:
  - загружены **3 выбранных CSV** из набора HW07 и выделены признаки (а `sample_id` не используется как признак);
  - сделан явный препроцессинг (scaling обязательно; обработка пропусков/категориальных – если есть);
  - для каждого датасета сравниваются минимум 2 метода (KMeans + DBSCAN или Agglomerative);
  - посчитаны внутренние метрики (silhouette / DB / CH) и корректно интерпретированы;
  - построены графики подбора параметров и PCA(2D)-визуализации кластеров;
  - выполнена проверка устойчивости (хотя бы для одного датасета) и сделаны выводы;

- отчётом `report.md`, заполненным по шаблону `S07-hw-report-template.md`;

- папкой `artifacts/` с артефактами эксперимента:
  - `metrics_summary.json` и `best_configs.json`,
  - `labels/` с `sample_id,cluster_label` для лучших решений,
  - `figures/` с графиками (минимум по одному PCA(2D) на каждый датасет + графики подбора параметров).

---

## 6. Дополнительные материалы (опционально)

В папке `seminars/S07/extras/` лежат ноутбуки для самостоятельного углубления темы:

- `S07-extra-01-kohonen-self-organizing-map.ipynb` – карта Кохонена (SOM): интуиция, BMU/соседство, пример на изображении;
- `S07-extra-02-dimensionality-reduction-pca-tsne-ica.ipynb` – углубление по PCA/t-SNE + дополнительный метод ICA.

Эти материалы **не входят в обязательную часть S07** и **не требуются для HW07**, но могут быть полезны:

- тем, кто хочет лучше понимать визуализацию и структуру данных в многомерных пространствах;
- тем, кто планирует более "исследовательскую" часть проекта (поиск структуры, сегментация, разведка данных).

---
