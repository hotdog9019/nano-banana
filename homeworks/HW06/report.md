# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

**Выбранный датасет:** `S06-hw-dataset-04.csv`

**Размер:** 25000 строк × 62 столбца

**Целевая переменная:** `target` (бинарная классификация: 0 и 1)
- Класс 0 (большинство): 95.08%
- Класс 1 (меньшинство): 4.92%

**Признаки:** 
- 60 числовых признаков (`f01` – `f60`)
- Столбец `id` (не используется как признак)
- Пропусков нет
- Все признаки непрерывные (тип: float64)

**Особенности:** 
Датасет имеет **сильный дисбаланс классов** с соотношением примерно 95:5, что типично для задач обнаружения аномалий (fraud detection, редкие события). Это критично учитывать при выборе метрик — accuracy может быть обманчива, так как модель может достичь 95% точности, просто всегда предсказывая класс большинства.

---

## 2. Protocol

### Разбиение данных
- **Train/Test split:** 75% / 25% (`test_size=0.25`)
  - Train: 18750 объектов
  - Test: 6250 объектов
- **Стратификация:** применена (`stratify=y`) для сохранения пропорций классов
  - Train: класс 0 = 95.08%, класс 1 = 4.92%
  - Test: класс 0 = 95.09%, класс 1 = 4.91%
- **Random state:** 42 (для воспроизводимости)

**Обоснование:** Стратификация критична при дисбалансе — гарантирует, что в train и test будут одинаковые доли классов, что особенно важно для редкого класса 1, который составляет менее 5%.

### Подбор гиперпараметров
- **Метод:** GridSearchCV
- **Cross-Validation:** 5-fold CV на train
- **Оптимизируемая метрика:** `roc_auc` (лучше подходит для дисбаланса, чем accuracy)
- **Важно:** Все эксперименты с гиперпараметрами проводились **только на train**. Test использован **один раз** для финальной оценки.

### Метрики качества
1. **Accuracy** — доля правильных предсказаний (базовая метрика, но обманчива при дисбалансе)
2. **F1-score** — гармоническое среднее precision и recall (учитывает оба типа ошибок)
3. **ROC-AUC** — способность модели разделять классы при разных порогах (основная метрика для выбора модели)
4. **PR-AUC** (Average Precision) — дополнительная метрика, более информативная для дисбаланса

**Почему эти метрики уместны:**
- При дисбалансе 95/5 модель может достичь accuracy=95%, просто предсказывая всегда класс 0
- F1 и ROC-AUC показывают реальную способность модели различать классы
- PR-AUC особенно важна для дисбаланса, так как фокусируется на качестве предсказаний для редкого класса

---

## 3. Models

### Baseline модели

**1. DummyClassifier** (`strategy='most_frequent'`)
- Наивный baseline: всегда предсказывает класс большинства (0)
- Гиперпараметры: нет
- Результат: показывает нижнюю границу качества

**2. LogisticRegression** (с StandardScaler)
- Линейный baseline из предыдущих семинаров
- Pipeline: StandardScaler → LogisticRegression
- Гиперпараметры: `max_iter=1000`, `random_state=42`
- Показывает, насколько задача линейна

### Модели на основе деревьев

**3. DecisionTreeClassifier** (с контролем сложности)
- **Подбираемые гиперпараметры:**
  - `max_depth`: [3, 5, 7, 10, None]
  - `min_samples_leaf`: [1, 5, 10, 20]
  - `min_samples_split`: [2, 10, 20]
- **Цель:** показать важность регуляризации для предотвращения переобучения
- **Лучшие параметры:** определены через GridSearchCV на основе CV ROC-AUC

**4. RandomForestClassifier**
- **Подбираемые гиперпараметры:**
  - `n_estimators`: [50, 100, 200]
  - `max_depth`: [10, 20, None]
  - `min_samples_leaf`: [1, 5, 10]
  - `max_features`: ['sqrt', 'log2']
- **Механизм:** bagging + случайность по признакам → уменьшение variance
- **Лучшие параметры:** определены через GridSearchCV

**5. GradientBoostingClassifier**
- **Подбираемые гиперпараметры:**
  - `n_estimators`: [50, 100, 150]
  - `learning_rate`: [0.01, 0.1, 0.2]
  - `max_depth`: [3, 5, 7]
  - `min_samples_leaf`: [1, 5, 10]
- **Механизм:** последовательная коррекция ошибок → часто лучшее качество
- **Лучшие параметры:** определены через GridSearchCV

**6. StackingClassifier**
- **Базовые модели:**
  - RandomForestClassifier (n_estimators=100, max_depth=10)
  - GradientBoostingClassifier (n_estimators=100, max_depth=5)
  - DecisionTreeClassifier (max_depth=7)
- **Мета-модель:** LogisticRegression
- **CV:** 5-fold (встроено в StackingClassifier)
- **Цель:** проверить, даёт ли комбинация моделей улучшение

---

## 4. Results

### Финальные метрики на test

| Модель | Accuracy | F1-Score | ROC-AUC |
|--------|----------|----------|---------|
| **RandomForest (tuned)** | **0.9771** | **0.7849** | **0.9016** |
| GradientBoosting (tuned) | 0.9786 | 0.7362 | 0.8960 |
| StackingClassifier | 0.9786 | 0.7362 | 0.8960 |
| LogisticRegression + StandardScaler | 0.9627 | 0.4131 | 0.8397 |
| DecisionTree (tuned) | 0.9648 | 0.5133 | 0.7948 |
| DummyClassifier (most_frequent) | 0.9509 | 0.0000 | 0.5000 |

### Победитель

**Лучшая модель:** RandomForest (tuned)

**Критерий выбора:** максимальный ROC-AUC на test

**Метрики лучшей модели:**
- Accuracy: 0.9771 (97.71%)
- F1-Score: 0.7849 (78.49%)
- ROC-AUC: 0.9016 (90.16%)
- PR-AUC (Average Precision): 0.7647 (76.47%)

**Почему эта модель победила:**

Random Forest показал наилучший баланс между всеми метриками, достигнув ROC-AUC = 0.9016. Модель демонстрирует отличную способность разделять классы (ROC-AUC > 0.9), при этом показывая высокий F1-score = 0.78, что говорит о хорошем балансе между precision и recall для редкого класса.

Интересно отметить, что GradientBoosting и StackingClassifier показали чуть выше accuracy (0.9786 vs 0.9771), но **ниже ROC-AUC** (0.8960 vs 0.9016). Это классический пример того, почему accuracy обманчива при дисбалансе — модели с более высокой accuracy могут хуже разделять классы, что видно по более низкому ROC-AUC.

Random Forest через механизм bagging (усреднение множества деревьев) и случайность по признакам смог эффективно снизить variance отдельных деревьев, что привело к лучшей генерализации. Высокий PR-AUC (0.7647) также подтверждает, что модель хорошо работает именно на редком классе 1.

---

## 5. Analysis

### Устойчивость моделей

Проверка устойчивости не проводилась (опциональная часть). При одном фиксированном random_state=42 результаты полностью воспроизводимы. Все артефакты и метрики сохранены для возможности повторения эксперимента.

### Анализ ошибок

**Classification Report для RandomForest:**

```
              precision    recall  f1-score   support

     Class 0       0.97      1.00      0.98      5943
     Class 1       0.99      0.40      0.57       307

    accuracy                           0.97      6250
   macro avg       0.98      0.70      0.78      6250
weighted avg       0.97      0.97      0.96      6250
```

**Интерпретация:**

**Класс 0 (большинство, 5943 объекта):**
- Precision = 0.97 — из предсказанных "0" 97% реально были "0"
- Recall = 1.00 — модель нашла практически все случаи класса 0
- F1 = 0.98 — отличное качество для класса большинства

**Класс 1 (меньшинство, 307 объектов):**
- Precision = 0.99 — из предсказанных "1" 99% реально были "1" (почти нет ложных тревог!)
- Recall = 0.40 — модель нашла только 40% случаев класса 1 (пропустила 60%)
- F1 = 0.57 — умеренное качество из-за низкого recall

**Ключевые наблюдения:**

1. **Trade-off между precision и recall:** Модель выбрала стратегию "высокая precision, низкий recall" для класса 1. Это означает, что когда модель предсказывает класс 1, она почти всегда права (99%), но она делает это редко, пропуская 60% случаев.

2. **Для fraud detection** такой баланс не идеален — лучше иметь чуть больше ложных тревог (lower precision), но находить больше реальных случаев (higher recall). Это можно улучшить через:
   - Настройку порога классификации (threshold tuning)
   - Использование `class_weight='balanced'`
   - Применение SMOTE для балансировки классов

3. **Дисбаланс сильно влияет:** При 95:5 модель "осторожничает" с предсказанием редкого класса. Высокий macro avg recall (0.70) скрывает проблему низкого recall для класса 1.

### Интерпретация модели

**Permutation Importance** (Top-15 признаков для RandomForest):

| Признак | Importance Mean | Importance Std |
|---------|-----------------|----------------|
| f54 | 0.017282 | 0.002550 |
| f41 | 0.012510 | 0.002770 |
| f13 | 0.012159 | 0.003904 |
| f53 | 0.008915 | 0.005284 |
| f25 | 0.008824 | 0.002835 |
| f08 | 0.008212 | 0.003215 |
| f33 | 0.008010 | 0.003845 |
| f58 | 0.006671 | 0.003902 |
| f38 | 0.006274 | 0.003101 |
| f47 | 0.005984 | 0.004305 |
| f11 | 0.005768 | 0.003202 |
| f04 | 0.005573 | 0.002509 |
| f50 | 0.004832 | 0.001872 |
| f36 | 0.004451 | 0.006196 |
| f52 | 0.004267 | 0.002574 |

**Выводы:**

1. **Концентрация важности на топ-признаках:** 
   - f54 является наиболее важным признаком (importance = 0.0173), при его перемешивании ROC-AUC падает на 1.73%
   - Топ-3 признака (f54, f41, f13) вносят суммарно ~4.2% в предсказательную силу
   - Это говорит о том, что есть несколько ключевых признаков, которые сильнее других влияют на разделение классов

2. **Распределение важности умеренно концентрированное:** 
   - Разница между топ-1 и топ-15 не очень большая (0.0173 vs 0.0043)
   - Модель использует информацию из многих признаков, а не полагается исключительно на 2-3 ключевых
   - Это характерно для Random Forest — случайность по признакам заставляет модель искать альтернативные пути к правильным предсказаниям

3. **Стабильность оценок:** 
   - Большинство топ-признаков имеют относительно низкий std (0.002-0.004)
   - f53 и f36 имеют более высокий std (0.0053 и 0.0062), что может указывать на:
     - Корреляцию с другими признаками
     - Различное использование в разных деревьях ансамбля
   
4. **Практическое значение:**
   - При необходимости уменьшения размерности можно сфокусироваться на топ-20 признаках
   - Признаки с importance < 0.001 потенциально можно исключить без существенной потери качества
   - Высокая importance f54, f41, f13 делает их кандидатами для детального анализа предметными экспертами

---

## 6. Conclusion

**Основные выводы:**

1. **Деревья легко переобучаются, ансамбли решают проблему:**
   DecisionTree показал ROC-AUC = 0.7948, что значительно ниже ансамблей (Random Forest = 0.9016, GradientBoosting = 0.8960). Это подтверждает, что отдельные деревья имеют высокую variance, а ансамбли через bagging или boosting эффективно её снижают. Random Forest улучшил результат на **+10.7 п.п. ROC-AUC** относительно отдельного дерева.

2. **Random Forest vs Boosting — победил bagging:**
   Неожиданно Random Forest (0.9016) показал лучший ROC-AUC, чем Gradient Boosting (0.8960), хотя обычно boosting превосходит bagging. Это может объясняться тем, что на данном датасете случайность по признакам (Random Forest) оказалась эффективнее последовательной коррекции ошибок (Boosting), возможно, из-за наличия множества слабо коррелированных признаков.

3. **Accuracy обманчива при дисбалансе:**
   Критический урок: модели с accuracy 0.9786 (GB, Stacking) уступили модели с accuracy 0.9771 (RF) по ROC-AUC. При дисбалансе 95:5 высокая accuracy может достигаться за счёт правильного предсказания класса большинства, но это не означает лучшей способности разделять классы. **F1, ROC-AUC, PR-AUC — правильные метрики для выбора модели.**

4. **Честный ML-протокол критичен для доверия к результатам:**
   Подбор гиперпараметров через 5-fold CV на train с оптимизацией по ROC-AUC + однократная оценка на test обеспечили объективную оценку качества. Фиксация random_state=42 на всех этапах (split, модели, CV) гарантирует полную воспроизводимость. Все артефакты (модели, метрики, графики) сохранены для аудита эксперимента.

5. **Интерпретируемость через permutation importance:**
   Анализ важности признаков показал, что модель опирается на разнообразную информацию (топ-15 признаков вносят суммарно ~11% importance), а не на 1-2 критичных признака. Это делает модель более устойчивой к изменениям в данных. Признаки f54, f41, f13 — ключевые для разделения классов и заслуживают внимания при интерпретации предсказаний.

6. **Precision-Recall trade-off для fraud detection:**
   RandomForest достиг precision=0.99 для класса 1, но recall=0.40, что означает пропуск 60% случаев. Для production-системы обнаружения fraud необходима дополнительная настройка: threshold tuning для увеличения recall, использование class_weight='balanced', или применение техник балансировки (SMOTE). Текущая модель хороша для задач, где критична точность детекции, но допустим пропуск части случаев.