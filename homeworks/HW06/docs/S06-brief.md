# Семинар 06 – Деревья решений и ансамбли (Bagging / Random Forest / Boosting / Stacking)

## 1. Место в курсе

Шестой семинар курса «Инженерия Искусственного Интеллекта».

Опирается на лекцию **L06** (деревья решений и ансамбли) и закрепляет экспериментальную дисциплину, которую студенты наработали в **S05** (baseline → честная оценка → фиксация результатов).  
Если S05 был "первым честным ML-экспериментом" на линейных моделях, то S06 – это шаг к моделям, которые:

- естественно работают с **нелинейностями**;
- дают сильное качество "из коробки" на табличных данных;
- требуют аккуратного контроля переобучения и корректного протокола оценки.

Домашнее задание по семинару – **HW06**, формальное описание находится в файле `seminars/S06/S06-homework.md`.

---

## 2. Цели семинара

После семинара и выполнения домашнего задания студент:

- понимает, что такое **дерево решений** как модель правил (*если… то…*), и почему "свободное" дерево почти всегда переобучается;
- умеет контролировать сложность дерева с помощью ключевых гиперпараметров (`max_depth`, `min_samples_leaf`, `ccp_alpha`);
- понимает идею ансамблей и их различия:
  - **bagging** как способ уменьшить variance;
  - **Random Forest** как bagging деревьев + случайность по признакам;
  - **boosting** как последовательное улучшение качества за счёт исправления ошибок;
  - (опционально) **stacking** как комбинация разных моделей через метамодель и why-CV-matters;
- умеет собрать **минимальный, но честный** ML-эксперимент для сравнения моделей:
  - фиксированный train/test;
  - CV на train для подбора гиперпараметров;
  - единый набор метрик;
  - сохранение артефактов (метрики/параметры/модель/графики);
- понимает, почему на дисбалансных задачах "одной accuracy недостаточно", и как метрики влияют на выводы.

---

## 3. Краткое содержание

1. **Вступление и связь с S05**
   - напоминание: что такое baseline и зачем он нужен;
   - что такое честная оценка (train/test + CV на train);
   - постановка задач S06: перейти от линейных моделей к деревьям и ансамблям, сохранив дисциплину эксперимента.

2. **Demo 1: Decision Tree – механика и переобучение**
   - дерево как последовательность разбиений и правил;
   - демонстрация переобучения (глубина/листья);
   - контроль сложности: `max_depth`, `min_samples_leaf`;
   - обрезка по cost-complexity pruning (`ccp_alpha`) как аккуратная "ручка";
   - краткая интерпретация (на уровне intuition + простая важность признаков).

   Файл: `S06-demo-01-decision-tree.ipynb`

3. **Demo 2: Bagging и Random Forest – устойчивость через разнообразие**
   - bootstrap-интуиция (почему в bootstrap-выборке ~63% уникальных объектов);
   - bagging деревьев как уменьшение variance;
   - Random Forest: почему добавление случайности по признакам делает ансамбль сильнее;
   - OOB-оценка (out-of-bag) как инженерный "быстрый индикатор";
   - демонстрация стабильности при разных `random_state`.

   Файл: `S06-demo-02-bagging-random-forest.ipynb`

4. **Demo 3: Boosting и Stacking – качество и композиция моделей**
   - boosting как последовательный ансамбль:
     - AdaBoost (идея "подсветить" сложные объекты);
     - Gradient Boosting / HistGradientBoosting (идея "шагами уменьшаем loss");
   - stacking как метамодель над предсказаниями базовых моделей;
   - короткая демонстрация, почему "наивный" стекинг опасен (утечка) и зачем нужны out-of-fold предсказания.

   Файл: `S06-demo-03-boosting-stacking.ipynb`

5. **Demo 4: Инженерный эксперимент – единый протокол сравнения**
   - baseline: Dummy + LogisticRegression;
   - модели недели 6: дерево / лес / бустинг / (опционально) стекинг;
   - CV-подбор параметров на train;
   - финальная оценка на test;
   - фиксация артефактов: метрики, параметры, графики, сохранённая модель;
   - permutation importance для интерпретации лучшей модели.

   Файл: `S06-demo-04-experiments.ipynb`

---

## 4. Формат проведения

Семинар проводится в формате "короткая рамка → серия демо → инженерная сборка → постановка HW06".

- **Короткий разбор (начало занятия)**:
  - связь S06 с L06 и S05 (baseline + честная оценка);
  - ключевой вопрос семинара: "почему одиночное дерево нестабильно, и как ансамбли это лечат?"

- **Практическая часть (основное время, live-coding + обсуждение)**:
  - 4 ноутбука-демонстрации (по нарастающей сложности):
    1) дерево и переобучение;
    2) bagging и random forest;
    3) boosting и stacking;
    4) инженерный эксперимент и фиксация результатов;
  - по ходу – короткие контрольные вопросы:
    - где и почему возникает переобучение дерева;
    - чем bagging отличается от boosting "по идее";
    - почему random forest устойчивее одиночного дерева;
    - где можно "случайно обмануть себя" в стекинге.

- **Постановка домашнего задания (финал)**:
  - демонстрация ожидаемой структуры `homeworks/HW06/`;
  - объяснение выбора датасета (4 CSV на выбор);
  - акцент: "важна не только метрика, но и протокол, и артефакты эксперимента".

---

## 5. Результат для студента

К концу семинара студент:

- понимает, как деревья и ансамбли "выигрывают" у линейных моделей на нелинейных зависимостях;
- умеет контролировать переобучение дерева и понимает, почему ансамбли обычно стабильнее;
- видит полный цикл сравнения моделей в одном инженерном протоколе.

После выполнения HW06 у студента в репозитории есть папка `homeworks/HW06/` с:

- ноутбуком `HW06.ipynb`, где:
  - загружен выбранный CSV (`S06-hw-dataset-01.csv` … `S06-hw-dataset-04.csv`);
  - выделены признаки и таргет `target` (и исключён `id` из признаков);
  - выполнен train/test-сплит с фиксированным `random_state` и `stratify` (где уместно);
  - построены baseline’ы (Dummy + LogisticRegression);
  - обучены и оценены модели недели 6 (дерево + лес + boosting; опционально stacking);
  - проведён подбор гиперпараметров на train через CV;
  - посчитаны метрики (минимум accuracy/F1 и ROC-AUC для бинарных задач, с корректной оговоркой для мультикласса);
  - построены диагностические графики (ROC/PR по ситуации, confusion matrix);
  - выполнена интерпретация лучшей модели через permutation importance (top-N);

- отчётом `report.md`, заполненным по шаблону `S06-hw-report-template.md`;

- папкой `artifacts/` с артефактами эксперимента:
  - `metrics_test.json` (или `.csv`),
  - `search_summaries.json`,
  - `best_model.joblib` и `best_model_meta.json`,
  - `figures/` (минимум 2 картинки).

---

## 6. Дополнительные материалы (опционально)

Для самостоятельного углубления (не обязательная часть):

- PR-кривые и `average_precision_score` для дисбалансных задач (особенно полезно для `S06-hw-dataset-04.csv`);
- калибровка вероятностей (`CalibratedClassifierCV`) и сравнение "сырых" vs калиброванных вероятностей;
- расширенная интерпретация ансамблей (SHAP для бустинга/леса – при наличии времени и интереса);
- измерение времени обучения/инференса и обсуждение компромисса "качество ↔ скорость".

---

### Дополнительные материалы (опционально)

В папке `seminars/S06/extras/` лежат ноутбуки с дополнительными примерами по деревьям решений и ансамблям:

- дерево решений (механика разбиений, переобучение, контроль сложности);
- случайный лес (устойчивость, важные гиперпараметры, OOB-идея);
- беггинг (bootstrap-логика и снижение variance);
- бустинг (последовательное улучшение качества, ключевые "ручки");
- стекинг (метамодель, out-of-fold логика и типичные ошибки).

Эти материалы **не входят в обязательную часть S06**, но могут быть полезны:

- тем, кто хочет глубже разобраться в ансамблях и подготовиться к более "взрослым" табличным задачам;
- при выполнении HW06 (особенно для датасета с дисбалансом) и при подготовке к последующим семинарам.

---
