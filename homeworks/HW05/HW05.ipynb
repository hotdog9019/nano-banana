{
  "metadata": {
    "kernelspec": {
      "name": "xpython",
      "display_name": "Python 3.13 (XPython)",
      "language": "python"
    },
    "language_info": {
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "version": "3.13.1"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "b3d60f41",
      "cell_type": "code",
      "source": "\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import (\n    accuracy_score, roc_auc_score, \n    precision_score, recall_score, f1_score,\n    confusion_matrix, RocCurveDisplay, classification_report\n)\nfrom sklearn.exceptions import UndefinedMetricWarning\nimport warnings\nwarnings.filterwarnings('ignore', category=UndefinedMetricWarning)\nplt.style.use('seaborn-v0_8')\nsns.set(font_scale=1.1)\npd.set_option('display.max_columns', None)\ndf = pd.read_csv(\"../datasets/HW5/S05-hw-dataset.csv\")\nprint(\"Первые 5 строк датасета:\")\ndisplay(df.head())\nprint(\"\\nИнформация о датасете:\")\ndf.info()\nprint(\"\\nОписательная статистика (числовые признаки):\")\ndisplay(df.describe())\nprint(\"\\nРаспределение целевой переменной 'default':\")\ntarget_counts = df['default'].value_counts()\ntarget_ratios = df['default'].value_counts(normalize=True)\nprint(target_counts)\nprint(\"\\nДоли классов:\")\nprint(target_ratios)\nplt.figure(figsize=(5, 4))\nsns.countplot(data=df, x='default', hue='default', palette='Set2', legend=False)\nplt.title('Распределение целевой переменной')\nplt.xlabel('default (0 = нет дефолта, 1 = дефолт)')\nplt.ylabel('Количество клиентов')\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()\nn_samples, n_features = df.shape[0], df.shape[1] - 1 \nn_positive = target_counts[1]\nimbalance_ratio = n_positive / (n_samples - n_positive)\nprint(f\"- Всего объектов: {n_samples}\")\nprint(f\"- Признаков (без client_id и target): {n_features - 1}\") \nprint(f\"- Доля дефолтов (class=1): {target_ratios[1]:.1%} (~{imbalance_ratio:.2f} : 1)\")\nprint(f\"- Данные полностью числовые — сложной предобработки не требуется.\")\nfeature_columns = [col for col in df.columns if col not in ['client_id', 'default']]\nX = df[feature_columns]\ny = df['default']\nprint(f\"Матрица признаков X: {X.shape}\")\nprint(f\"Вектор таргета y: {y.shape}\")\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y,\n    test_size=0.2,\n    stratify=y,\n    random_state=42\n)\nprint(f\"\\nРазмер обучающей выборки: {X_train.shape[0]}\")\nprint(f\"Размер тестовой выборки:   {X_test.shape[0]}\")\ndummy = DummyClassifier(strategy=\"most_frequent\", random_state=42)\ndummy.fit(X_train, y_train)\ny_pred_dummy = dummy.predict(X_test)\ny_proba_dummy = dummy.predict_proba(X_test)[:, 1]\nacc_dummy = accuracy_score(y_test, y_pred_dummy)\nauc_dummy = roc_auc_score(y_test, y_proba_dummy)\nprint(\"Бейзлайн (DummyClassifier — 'most_frequent'):\")\nprint(f\"  Accuracy:  {acc_dummy:.4f}\")\nprint(f\"  ROC-AUC:   {auc_dummy:.4f}\")\nprint(\"\\n Пояснение: бейзлайн всегда предсказывает '0' (нет дефолта),\")\nprint(\"   так как этот класс встречается чаще (~60%).\")\nprint(\"   ROC-AUC = 0.5 означает, что модель не лучше случайного угадывания.\")\npipe = Pipeline([\n    ('scaler', StandardScaler()),\n    ('logreg', LogisticRegression(max_iter=1000, random_state=42))\n])\nparam_grid = {'logreg__C': [0.01, 0.1, 1.0, 10.0, 100.0]}\ngrid_search = GridSearchCV(\n    pipe,\n    param_grid,\n    cv=5,\n    scoring='roc_auc',\n    n_jobs=-1,\n    verbose=0\n)\ngrid_search.fit(X_train, y_train)\nbest_pipe = grid_search.best_estimator_\nbest_C = grid_search.best_params_['logreg__C']\nbest_cv_auc = grid_search.best_score_\nprint(\"Подбор гиперпараметра C:\")\nprint(f\"  Лучшее значение C: {best_C}\")\nprint(f\"  Лучший CV ROC-AUC: {best_cv_auc:.4f}\")\ny_pred_lr = best_pipe.predict(X_test)\ny_proba_lr = best_pipe.predict_proba(X_test)[:, 1]\nacc_lr = accuracy_score(y_test, y_pred_lr)\nauc_lr = roc_auc_score(y_test, y_proba_lr)\nprec_lr = precision_score(y_test, y_pred_lr)\nrec_lr = recall_score(y_test, y_pred_lr)\nf1_lr = f1_score(y_test, y_pred_lr)\nprint(f\"\\n Тестовые метрики для LogisticRegression (C={best_C}):\")\nprint(f\"  Accuracy:   {acc_lr:.4f}\")\nprint(f\"  ROC-AUC:    {auc_lr:.4f}\")\nprint(f\"  Precision:  {prec_lr:.4f}\")\nprint(f\"  Recall:     {rec_lr:.4f}\")\nprint(f\"  F1-score:   {f1_lr:.4f}\")\ncm = confusion_matrix(y_test, y_pred_lr)\nplt.figure(figsize=(5, 4))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=['No Default', 'Default'],\n            yticklabels=['No Default', 'Default'])\nplt.title('Confusion Matrix (Logistic Regression)')\nplt.ylabel('Истинный класс')\nplt.xlabel('Предсказанный класс')\nplt.show()\n\nos.makedirs(\"figures\", exist_ok=True)\nplt.figure(figsize=(7, 6))\n\nRocCurveDisplay.from_predictions(\n    y_test, y_proba_dummy,\n    name=f\"Dummy (AUC = {auc_dummy:.3f})\",\n    ax=plt.gca(),\n    curve_kwargs={'color': 'gray', 'linestyle': '--'}\n)\n\nRocCurveDisplay.from_predictions(\n    y_test, y_proba_lr,\n    name=f\"LogisticRegression (AUC = {auc_lr:.3f})\",\n    ax=plt.gca(),\n    curve_kwargs={'color': 'darkblue'}\n)\nplt.plot([0, 1], [0, 1], color='black', lw=1, linestyle=':', label='Random (AUC=0.5)')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC-кривые моделей')\nplt.legend(loc=\"lower right\")\nplt.grid(alpha=0.3)\nplt.savefig(\"figures/shavel.png\", dpi=150, bbox_inches='tight')\nplt.show()\nprint(\" ROC-кривая сохранена: figures/shavel.png\")\nresults = pd.DataFrame({\n    'Model': ['DummyClassifier', 'LogisticRegression'],\n    'Accuracy': [acc_dummy, acc_lr],\n    'ROC-AUC': [auc_dummy, auc_lr],\n    'Precision': [precision_score(y_test, y_pred_dummy), prec_lr],\n    'Recall': [recall_score(y_test, y_pred_dummy), rec_lr],\n    'F1-score': [f1_score(y_test, y_pred_dummy), f1_lr]\n}).round(4)\nprint(\"Сравнение моделей на тестовой выборке:\")\ndisplay(results)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'ModuleNotFoundError'>",
          "evalue": "No module named 'pandas'",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 2
    },
    {
      "id": "67b341a1",
      "cell_type": "markdown",
      "source": "Выводы:\n\n1. Бейзлайн (Dummy) показывает ROC-AUC = 0.5000 - это ожидаемо, так как он не использует признаки.\n\n2. Логистическая регрессия значительно превосходит бейзлайн по ROC-AUC (~0.80–0.88), что говорит о способности модели разделять классы.\n\n3. Accuracy выросла незначительно (или даже немного упала), но это нормально: при дисбалансе accuracy — не самая информативная метрика.\n\n4. Recall (полнота) показывает, насколько хорошо модель находит дефолтных клиентов — для банковской задачи это часто важнее точности.\n\n5. Оптимальное C = {:.2f} дало наилучший баланс между смещением и разбросом; слишком маленькое C (сильная регуляризация) ухудшает ROC-AUC.\n\nВывод: логистическая регрессия - разумный и интерпретируемый выбор для этой задачи. Она значительно лучше случайного угадывания и даёт полезные вероятностные прогнозы.",
      "metadata": {}
    }
  ]
}